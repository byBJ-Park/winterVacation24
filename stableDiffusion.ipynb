{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionBlock(layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.q_proj = layers.Dense(channels)\n",
    "        self.k_proj = layers.Dense(channels)\n",
    "        self.v_proj = layers.Dense(channels)\n",
    "        self.proj  = layers.Dense(channels)\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        # Image feature map\n",
    "        B, H, W, C = x.shape\n",
    "        residual = x\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        context = self.norm(context)\n",
    "        \n",
    "        x_flat = tf.reshape(x, (B, H*W, C))\n",
    "        q_concat = tf.concat([x_flat, context], axis=1)\n",
    "        q = self.q_proj(q_concat) # Query (B, H*W+N, C)\n",
    "        \n",
    "        k = self.k_proj(context) # Key (B, N, C)\n",
    "        v = self.v_proj(context) # Value (B, N, C)\n",
    "        \n",
    "        attention = tf.matmul(q, k, transpose_b=True), tf.math.sqrt(tf.cast(C, tf.float32))\n",
    "        attention = tf.nn.softmax(attention, axis=-1)\n",
    "        \n",
    "        out = tf.matmul(attention, v)\n",
    "        out = tf.reshape(out, (B, H, W, C))\n",
    "        \n",
    "        out = self.proj(out)\n",
    "        return out + residual # Skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimestepEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, time_dim):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.dense1 = layers.Dense(time_dim, activation='swish')\n",
    "        self.dense2 = layers.Dense(time_dim, activation='swish')\n",
    "\n",
    "    def call(self, t):\n",
    "        half_dim = self.time_dim // 2\n",
    "        emb = tf.range(half_dim, dtype=tf.float32)\n",
    "        emb = tf.exp(-tf.math.log(10000.0) * emb / half_dim)\n",
    "        emb = tf.cast(t, dtype=tf.float32)[:, None] * emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        emb = tf.pad(emb, [[0, 0], [0, self.time_dim % 2]])  # For odd time_dim\n",
    "\n",
    "        emb = self.dense1(emb)\n",
    "        emb = self.dense2(emb)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedUNet(Model):\n",
    "    def __init__(self, time_dim=256):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.time_embed = TimestepEmbedding(time_dim)\n",
    "        \n",
    "        self.enc1 = self.make_encoder_block(64)\n",
    "        self.enc2 = self.make_encoder_block(128)\n",
    "        self.enc3 = self.make_encoder_block(256)\n",
    "        \n",
    "        self.bottleneck = tf.keras.Sequential([\n",
    "            CrossAttentionBlock(256),\n",
    "            layers.Conv2D(256, 3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('swish')\n",
    "        ])\n",
    "        \n",
    "        self.dec3 = self.make_decoder_block(128)\n",
    "        self.dec2 = self.make_decoder_block(64)\n",
    "        self.dec1 = self.make_decoder_block(64)\n",
    "        self.final = layers.Conv2D(3, 1, activation='tanh')\n",
    "        \n",
    "    def make_encoder_block(self, channels):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.Conv2D(channels, 3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('swish'),\n",
    "            layers.Conv2D(channels, 3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('swish'),\n",
    "            layers.MaxPooling2D(2)\n",
    "        ])\n",
    "        \n",
    "    def make_decoder_block(self, channels):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(channels, 3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('swish'),\n",
    "            layers.Conv2D(channels, 3, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('swish')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, t, text_embeddings):\n",
    "        t = self.time_embed(t)\n",
    "        t = tf.reshape(t, (-1, 1, 1, self.time_dim))\n",
    "        \n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        \n",
    "        # Bottleneck with Cross-Attention\n",
    "        middle = self.bottleneck(e3+t, context=text_embeddings)\n",
    "        \n",
    "        # Decoder with skip connection\n",
    "        x = self.dec3(tf.concat([middle, e3], axis=-1))\n",
    "        x = self.dec2(tf.concat([x, e2], axis=-1))\n",
    "        x = self.dec1(tf.concat([x, e1], axis=-1))\n",
    "        \n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedStableDiffusion(Model):\n",
    "    def __init__(self, img_size=64, time_steps=1000):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "        # Noise scheduling\n",
    "        self.beta = np.linspace(0.0001, 0.02, time_steps)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = tf.constant(np.cumprod(self.alpha), dtype=tf.float32)\n",
    "        \n",
    "        self.unet = ImprovedUNet()\n",
    "        \n",
    "    def diffusion_schedule(self, n):\n",
    "        return tf.gather(self.alpha_bar, n)\n",
    "    \n",
    "    def forward_diffusion(self, x, t):\n",
    "        alpha_bar = self.diffusion_schedule(t)\n",
    "        alpha_bar = tf.reshape(alpha_bar, (-1, 1, 1, 1))\n",
    "        \n",
    "        noise = tf.random.normal(x.shape)\n",
    "        noisy_x = tf.sqrt(alpha_bar) * x + tf.sqrt(1 - alpha_bar) * noise\n",
    "        return noisy_x, noise\n",
    "    \n",
    "    def call(self, x, training=True, text_embeddings=None):\n",
    "        if text_embeddings is None:\n",
    "            raise ValueError(\"text_embeddings must be provided for cross-attention.\")\n",
    "        \n",
    "        b = tf.shape(x)[0]\n",
    "        t = tf.random.uniform((b,), 0, self.time_steps, dtype=tf.float32)\n",
    "        \n",
    "        x_noisy, noise = self.forward_diffusion(x, t)\n",
    "        \n",
    "        pred_noise = self.unet(x_noisy, t, text_embeddings)\n",
    "        \n",
    "        if training:\n",
    "            return pred_noise, noise\n",
    "        else:\n",
    "            return self.sample(b, text_embeddings)\n",
    "        \n",
    "    def sample(self, batch_size, text_embeddings):\n",
    "        x = tf.random.normal((batch_size, self.img_size, self.img_size, 3))\n",
    "        \n",
    "        for t in range(self.time_steps-1, -1, -1):\n",
    "            t_batch = tf.fill((batch_size), t)\n",
    "            pred_noise = self.unet(x, t_batch, text_embeddings)\n",
    "            \n",
    "            alpha = self.alpha[t]\n",
    "            alpha_bar = self.alpha_bar[t]\n",
    "            beta = self.beta[t]\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = tf.random.normal(x.shape)\n",
    "            else:\n",
    "                noise = 0\n",
    "                \n",
    "            x = (1 / tf.sqrt(alpha) * (x - ((1-alpha) / tf.sqrt(1-alpha_bar))*pred_noise) + tf.sqrt(beta)*noise)    \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
